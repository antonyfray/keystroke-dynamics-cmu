{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TODO - ROC curves, minimal equal error rate plot, evaulation of ROC over time (overlay with average?)\n",
    "# Implement gridsearch to optimise the model? (Use validation set of data)\n",
    "Working on this problem: https://www.cs.cmu.edu/~keystroke/.\n",
    "Supporting paper: http://www.cs.cmu.edu/~keystroke/KillourhyMaxion09.pdf\n",
    "\n",
    "Data comes from 51 subjects typing \".tie5Roanl\" 400 times across multiple sessions.\n",
    "\n",
    "Our goal is to develop a model which has a minimal equal error rate. \n",
    "\n",
    "(Diagram of minimal equal error rate https://api.intechopen.com/media/chapter/66135/media/F2.png).\n",
    "\n",
    "Questions that immediately need answering:\n",
    "- What type of problem is this (classification or regression)?\n",
    "- Has anyone attempted this problem before?\n",
    "    - If so, how did they approach it? \n",
    "        - Which detectors / feature sets / models did they use?\n",
    "        - What was successful about their approach? \n",
    "        - What were their limitations?\n",
    "- What do the features in the dataset represent?\n",
    "- Which do we prioritise - false poitives or false negatives (aka in this context: false-alarm rates and miss rates).\n",
    "    - From the literature (and common sense to be honest), we should prioritise lowering miss rates (it's better to lock out a user, than have a threat access the system).\n",
    "\n",
    "These were largely answered through reading the aforementioned paper, and doing some background reading and research.\n",
    "\n",
    "The aforementioned paper also detailed a method by which different detectors could be compared on the same dataset. So to evaluate how our 'new' model performs against its competitors, it makes sense to first implement a pre-existing model, then our new model, and compare performance under the same conditions.\n",
    "\n",
    "Note: The paper implemented the techniques using R (which I've not used before). Implementation in Python _should_ be the same, but there may be some underlying differences in R/Python's mathematics libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and file processing\n",
    "Let's import some relevant modules and see what the file's contents are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First, imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# for Manhattan detector, need cityblock distance\n",
    "from scipy.spatial.distance import cityblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv file and check what's inside\n",
    "df = pd.read_csv('DSL-StrongPasswordData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# 20,400 rows, 34 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "# Mean DD looks to be ~ double H and UD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subjects = df[\"subject\"].unique()\n",
    "print(subjects) \n",
    "# Confirmation there are 51 unique subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = df[\"sessionIndex\"].unique()\n",
    "print(sessions)\n",
    "# 400 times across 8 sessions means each subject typed the string ~ 50 times per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df.filter(['H.period','H.t','H.i','H.e','H.five','H.Shift.r','H.o','H.a','H.n','H.l','H.Return'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df.filter(['DD.period.t','DD.t.i','DD.i.e','DD.e.five','DD.five.Shift.r','DD.Shift.r.o','DD.o.a','DD.a.n','DD.n.l','DD.l.Return'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df.filter(['UD.period.t','UD.t.i','UD.i.e','UD.e.five','UD.five.Shift.r','UD.Shift.r.o','UD.o.a','UD.a.n','UD.n.l','UD.l.Return'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows - there aren't any, this is good\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df[\"H.period\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df[\"H.t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df[\"DD.period.t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df[\"DD.t.i\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df[\"UD.period.t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df[\"UD.t.i\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like there are some serious outliers with UD and DD, but H has a more even spread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident this is a classification problem, rather than a regression problem. \n",
    "\n",
    "Firstly, let's approach this using standard anomaly detection practices - we will train a model to recognise a certain user's typing pattern, and then test it against the remaining user's samples, from which we can obtain an anomaly score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    #print('Training new model for subject {}'.format(subject))\n",
    "    real_user = df.loc[df.subject == subject]\n",
    "    fake_user = df.loc[df.subject != subject]\n",
    "\n",
    "    # We train our model using a genuine user's data\n",
    "    training_data = real_user[:200].loc[:, 'H.period':'H.Return']\n",
    "    \n",
    "    # To test our model, we need both more data from the original user, and imposter user data\n",
    "    genuine_user_data = real_user[200:].loc[:, 'H.period':'H.Return']\n",
    "    imposter_user_data = fake_user[:].loc[:, 'H.period':'H.Return']\n",
    "    \n",
    "    # Let's check dimensions of our training and testing tuples are the same...just in case\n",
    "    if training_data.shape != genuine_user_data.shape:\n",
    "        sys.exit(\"training_data and genuine_user_data shapes don't match: {} | {}\".format(training_data.shape, genuine_user_data.shape))\n",
    "    elif imposter_user_data.shape[0] != genuine_user_data.shape[0]*100:\n",
    "        sys.exit(\"imposter_user_data and genuine_user_data rows aren't 20000 and 200: {} | {}\".format(imposter_user_data.shape[0], genuine_user_data.shape[0]))\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    mean_vector = training_data.mean().values # store mean vector in a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let's implement the Manhattan detector first, and then later we can compare our model's performance to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Future Improvements\n",
    "Things that could be looked at in future:\n",
    "- Try multi-class classification vs anomaly detection.\n",
    "    - Rather than training with respect to one user's data, then testing against the rest, with MCC you could use multiple user's samples to form decision boundaries wherein users could be distinguished.\n",
    "- We have not accounted for correlations between dataset features (whereas in reality, DD values will be comprised of both H and UD components, implying correlation). We could retrain having normalised out these effects.\n",
    "- There appear to be a lot of outliers present in the UD and DD data (considering the box plots). We could use some sort of filter (see Manhattan filter detector) to remove these components, and see if performance improves.\n",
    "- Could implement hypothesis testing to verify our model is better than the others presented (rather than due to just random chance).\n",
    "- Could look at other keystroke data available online (as mentioned in the paper) - although if we were to integrate it, we'd have to ensure it was recorded under similar conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
