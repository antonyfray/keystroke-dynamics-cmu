{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TODO - ROC curves, minimal equal error rate plot, evaulation of ROC over time (overlay with average?)\n",
    "# Implement gridsearch to optimise the model? (Use validation set of data)\n",
    "Working on this problem: https://www.cs.cmu.edu/~keystroke/.\n",
    "Supporting paper: http://www.cs.cmu.edu/~keystroke/KillourhyMaxion09.pdf\n",
    "\n",
    "Data comes from 51 subjects typing \".tie5Roanl\" 400 times across multiple sessions.\n",
    "\n",
    "Our goal is to develop a model which has a minimal equal error rate. \n",
    "\n",
    "(Diagram of minimal equal error rate https://api.intechopen.com/media/chapter/66135/media/F2.png).\n",
    "\n",
    "Questions that immediately need answering:\n",
    "- What type of problem is this (classification or regression)?\n",
    "- Has anyone attempted this problem before?\n",
    "    - If so, how did they approach it? \n",
    "        - Which detectors / feature sets / models did they use?\n",
    "        - What was successful about their approach? \n",
    "        - What were their limitations?\n",
    "- What do the features in the dataset represent?\n",
    "- Which do we prioritise - false poitives or false negatives (aka in this context: false-alarm rates and miss rates).\n",
    "    - From the literature (and common sense to be honest), we should prioritise lowering miss rates (it's better to lock out a user, than have a threat access the system).\n",
    "\n",
    "These were largely answered through reading the aforementioned paper, and doing some background reading and research.\n",
    "\n",
    "The aforementioned paper also detailed a method by which different detectors could be compared on the same dataset. So to evaluate how our 'new' model performs against its competitors, it makes sense to first implement a pre-existing model, then our new model, and compare performance under the same conditions.\n",
    "\n",
    "Note: The paper implemented the techniques using R (which I've not used before). Implementation in Python _should_ be the same, but there may be some underlying differences in R/Python's mathematics libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and file processing\n",
    "Let's import some relevant modules and see what the file's contents are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First, imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "# for Manhattan detector, need cityblock distance\n",
    "from scipy.spatial.distance import cityblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>sessionIndex</th>\n",
       "      <th>rep</th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>...</th>\n",
       "      <th>H.a</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.0742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.2332</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>0.0945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.1629</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>0.2387</td>\n",
       "      <td>0.0813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.0818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject  sessionIndex  rep  H.period  DD.period.t  UD.period.t     H.t  \\\n",
       "0    s002             1    1    0.1491       0.3979       0.2488  0.1069   \n",
       "1    s002             1    2    0.1111       0.3451       0.2340  0.0694   \n",
       "2    s002             1    3    0.1328       0.2072       0.0744  0.0731   \n",
       "3    s002             1    4    0.1291       0.2515       0.1224  0.1059   \n",
       "4    s002             1    5    0.1249       0.2317       0.1068  0.0895   \n",
       "\n",
       "   DD.t.i  UD.t.i     H.i    ...        H.a  DD.a.n  UD.a.n     H.n  DD.n.l  \\\n",
       "0  0.1674  0.0605  0.1169    ...     0.1349  0.1484  0.0135  0.0932  0.3515   \n",
       "1  0.1283  0.0589  0.0908    ...     0.1412  0.2558  0.1146  0.1146  0.2642   \n",
       "2  0.1291  0.0560  0.0821    ...     0.1621  0.2332  0.0711  0.1172  0.2705   \n",
       "3  0.2495  0.1436  0.1040    ...     0.1457  0.1629  0.0172  0.0866  0.2341   \n",
       "4  0.1676  0.0781  0.0903    ...     0.1312  0.1582  0.0270  0.0884  0.2517   \n",
       "\n",
       "   UD.n.l     H.l  DD.l.Return  UD.l.Return  H.Return  \n",
       "0  0.2583  0.1338       0.3509       0.2171    0.0742  \n",
       "1  0.1496  0.0839       0.2756       0.1917    0.0747  \n",
       "2  0.1533  0.1085       0.2847       0.1762    0.0945  \n",
       "3  0.1475  0.0845       0.3232       0.2387    0.0813  \n",
       "4  0.1633  0.0903       0.2517       0.1614    0.0818  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in csv file and check what's inside\n",
    "df = pd.read_csv('DSL-StrongPasswordData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s002' 's003' 's004' 's005' 's007' 's008' 's010' 's011' 's012' 's013'\n",
      " 's015' 's016' 's017' 's018' 's019' 's020' 's021' 's022' 's024' 's025'\n",
      " 's026' 's027' 's028' 's029' 's030' 's031' 's032' 's033' 's034' 's035'\n",
      " 's036' 's037' 's038' 's039' 's040' 's041' 's042' 's043' 's044' 's046'\n",
      " 's047' 's048' 's049' 's050' 's051' 's052' 's053' 's054' 's055' 's056'\n",
      " 's057']\n"
     ]
    }
   ],
   "source": [
    "subjects = df[\"subject\"].unique()\n",
    "print(subjects) \n",
    "# Confirmation there are 51 unique subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident this is a classification problem, rather than a regression problem. \n",
    "\n",
    "Firstly, let's approach this using standard anomaly detection practices - we will train a model to recognise a certain user's typing pattern, and then test it against the remaining (i.e. imposter) samples, from which we can obtain an anomaly score.\n",
    "\n",
    "For simplicity, let's implement the Manhattan detector first, and then later we can compare our model's performance to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eer | eer2 = 0.24060000000000004 | 0.24 \n",
      "eer | eer2 = 0.47055 | 0.47 \n",
      "eer | eer2 = 0.23470000000000002 | 0.235 \n"
     ]
    }
   ],
   "source": [
    "eer_list = []\n",
    "for subject in subjects:\n",
    "    #print('Training new model for subject {}'.format(subject))\n",
    "    real_user = df.loc[df.subject == subject]\n",
    "    fake_user = df.loc[df.subject != subject]\n",
    "\n",
    "    # We train our model using a genuine user's data\n",
    "    training_data = real_user[:200].loc[:, 'H.period':'H.Return']\n",
    "    \n",
    "    # To test our model, we need both more data from the original user, and imposter user data\n",
    "    genuine_user_data = real_user[200:].loc[:, 'H.period':'H.Return']\n",
    "    imposter_user_data = fake_user[:].loc[:, 'H.period':'H.Return']\n",
    "    \n",
    "    # Let's check dimensions of our training and testing tuples are the same...just in case\n",
    "    if training_data.shape != genuine_user_data.shape:\n",
    "        sys.exit(\"training_data and genuine_user_data shapes don't match: {} | {}\".format(training_data.shape, genuine_user_data.shape))\n",
    "    elif imposter_user_data.shape[0] != genuine_user_data.shape[0]*100:\n",
    "        sys.exit(\"imposter_user_data and genuine_user_data rows aren't 20000 and 200: {} | {}\".format(imposter_user_data.shape[0], genuine_user_data.shape[0]))\n",
    "\n",
    "    # Train\n",
    "    mean_vector = training_data.mean().values # store mean vector in a numpy array to use with cityblock func below\n",
    "    \n",
    "    # Test - for each row (entry), compute cityblock distance between mean vector and test vector\n",
    "    user_dists = []\n",
    "    imposter_dists = []\n",
    "    for i in range(genuine_user_data.shape[0]):\n",
    "        dist = cityblock(genuine_user_data.iloc[i].values, mean_vector)\n",
    "        user_dists.append(dist)\n",
    "       \n",
    "    for i in range(imposter_user_data.shape[0]):\n",
    "        dist = cityblock(imposter_user_data.iloc[i].values, mean_vector)\n",
    "        imposter_dists.append(dist)\n",
    "        \n",
    "    # Evaluate - compute equal error rates\n",
    "    # Labels: 0 = user, 1 = imposter. We therefore need np arrays of 0s and 1s to same length as NSamples\n",
    "    labels = [0]*len(user_dists) + [1]*len(imposter_dists)\n",
    "    fpr, tpr, thresholds = roc_curve(labels, user_dists + imposter_dists) \n",
    "    \n",
    "    # plot ROC curve of each model. TODO can we get the average on here, as an identifiable colour? Below works btw\n",
    "    #plt.plot(fpr,tpr)\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    if subject == \"s005\":\n",
    "        break\n",
    "\n",
    "    # TPR = TP / (TP + FN) i.e. over total positives that shouldve been identified as true\n",
    "    # FPR = FP / (FP + TN) i.e. over total negatives that shouldve been identified as true\n",
    "    # TPR + FNR = 1\n",
    "    # FPR + TNR = 1\n",
    "    fnr = 1 - tpr\n",
    "    \n",
    "    # Equal error rate is where fnr = fpr (or minimum distance between them)      \n",
    "    # So we calculate the absolute difference between fnr and fpr and find where that's minimised\n",
    "    # Small differences are present depending on whether we do fnr[] or fpr[] as we aren't interpolating\n",
    "    eer = fnr[np.nanargmin(np.absolute(fnr-fpr))]\n",
    "    eer2 = fpr[np.nanargmin(np.absolute(fnr-fpr))]\n",
    "    print(\"eer | eer2 = {} | {} \".format(eer,eer2))\n",
    "    \n",
    "    eer_list.append(eer)\n",
    "    # TODO EER in an array, we wil calculate the average EER at the end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan average equal error rate = 0.31528333333333336\n"
     ]
    }
   ],
   "source": [
    "# Compute average eer\n",
    "print(\"Manhattan average equal error rate = {}\".format(np.mean(eer_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments on Manhattan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that there's so much ROC variation implies we could probably tidy the data a bit to improve the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
